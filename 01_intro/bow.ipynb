{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724dbd9c-e275-44db-b732-e08c70e46598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fed9ef-39f6-4e79-a3f4-2dea8c822866",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6de25-5cf9-436e-8d63-2a55f4735be9",
   "metadata": {},
   "source": [
    "## BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9399f90c-3fa3-4e00-b460-d3522d338e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(BoW, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "                                num_embeddings = vocab_size,\n",
    "                                embedding_dim = embedding_dim,\n",
    "                                device = device,\n",
    "                        )\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        self.bias = nn.Parameter(torch.zeros(embedding_dim, device=device), requires_grad=True)\n",
    "\n",
    "        \n",
    "    def forward(self, words):\n",
    "        out = self.embedding(words)\n",
    "        out = out.sum(dim=0) + self.bias\n",
    "        out = out.view(1, -1)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de87c1a5-9413-4e45-b0e3-b585fdcb5c04",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92942776-f4ba-47ab-87e6-3781aed1e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475d59c9-0302-4ed0-9dd8-aa55a03bf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line = f.readline().lower().strip().split(\" ||| \")\n",
    "                text_class, text = line[0], line[1]\n",
    "                yield ([w2i[word] for word in text.split(\" \")], t2i[text_class])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792e196b-33ee-48aa-b359-7dcb33f052af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "vocab_size = len(w2i)\n",
    "n_classes = len(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc5b1c2-95df-4631-a752-f814cb91276e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11402"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10acb59-09c4-42ff-baf9-030887a3889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "dev = list(read_dataset(\"../data/classes/dev.txt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f937f07",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed51871c-6bed-43c8-92fc-95977cd14091",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = BoW(vocab_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7026ebf4-d3d2-4a67-abcd-df6877fee696",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(bow_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5430cc2d-7060-4267-bf9f-f63ca0423ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Train loss: 1.3278593930942513\n",
      "Iteration 0 - Test accuracy: 0.2672727272727273\n",
      "Iteration 1 - Train loss: 1.0759641071816397\n",
      "Iteration 1 - Test accuracy: 0.27636363636363637\n",
      "Iteration 2 - Train loss: 0.8615163682510009\n",
      "Iteration 2 - Test accuracy: 0.2781818181818182\n",
      "Iteration 3 - Train loss: 0.7069003791077418\n",
      "Iteration 3 - Test accuracy: 0.2781818181818182\n",
      "Iteration 4 - Train loss: 0.5909722992027185\n",
      "Iteration 4 - Test accuracy: 0.2963636363636364\n",
      "Iteration 5 - Train loss: 0.5014758727509766\n",
      "Iteration 5 - Test accuracy: 0.30363636363636365\n",
      "Iteration 6 - Train loss: 0.43082522152232405\n",
      "Iteration 6 - Test accuracy: 0.3054545454545455\n",
      "Iteration 7 - Train loss: 0.37401477615296674\n",
      "Iteration 7 - Test accuracy: 0.30727272727272725\n",
      "Iteration 8 - Train loss: 0.32759979818790647\n",
      "Iteration 8 - Test accuracy: 0.3145454545454546\n"
     ]
    }
   ],
   "source": [
    "# Just 10 epochs as the goal is not to train a real model\n",
    "# but just to see if the implementation is working\n",
    "for i in range(10):\n",
    "    train_loss = 0\n",
    "    test_accuracy = 0\n",
    "    for words, sentence_class in train:\n",
    "        words = torch.tensor(words, device=device)\n",
    "        sentence_class = torch.tensor([sentence_class], device=device)\n",
    "        predictions = bow_model(words)\n",
    "        loss = loss_criterion(predictions, sentence_class)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Iteration {i} - Train loss: {train_loss/len(train)}\")\n",
    "    with torch.no_grad():\n",
    "        for words, sentence_class in dev:\n",
    "            words = torch.tensor(words, device=device)\n",
    "            predictions = bow_model(words)\n",
    "            predicted_class = np.argmax(predictions.detach().cpu().numpy())\n",
    "            if predicted_class == sentence_class:\n",
    "                test_accuracy += 1\n",
    "    print(f\"Iteration {i} - Test accuracy: {test_accuracy/len(dev)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
